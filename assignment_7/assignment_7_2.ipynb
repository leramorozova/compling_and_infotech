{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_7_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMbHQI6t94SPYskoyFZAwo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fc78a5f8a3d41008d73058f92b84f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_14e8a7b2184b4ed18ae255da4983786e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_607e584c47ce4e3989bb62d110c1dfa9",
              "IPY_MODEL_7c751954933f4e3fa62040e94e6284d7"
            ]
          }
        },
        "14e8a7b2184b4ed18ae255da4983786e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "607e584c47ce4e3989bb62d110c1dfa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29178b5f4cc940fea1c2c3bba8fd24ec",
            "_dom_classes": [],
            "description": "train epoch 1",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1686,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1686,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc187127d84a4ff38f7ceaad361247ef"
          }
        },
        "7c751954933f4e3fa62040e94e6284d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ddf26beedd634369b58ea748231c895f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1686/1686 [11:43&lt;00:00,  2.36it/s, loss=tensor(6.0464, device=&#x27;cuda:0&#x27;, grad_fn=&lt;DivBackward0&gt;)]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_060cfb2e8d4b444b813bac6677fa6d75"
          }
        },
        "29178b5f4cc940fea1c2c3bba8fd24ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc187127d84a4ff38f7ceaad361247ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddf26beedd634369b58ea748231c895f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "060cfb2e8d4b444b813bac6677fa6d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54542e1e57f842d5a5422c56fb170a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60564837af5d40779d2f91f236d8590c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_065a23d987944fa4a548289dae0c5acf",
              "IPY_MODEL_0e7318ef0d6d4fee87b892f20c8f5f77"
            ]
          }
        },
        "60564837af5d40779d2f91f236d8590c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "065a23d987944fa4a548289dae0c5acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c3c091a86984b1995ce7024b10747c7",
            "_dom_classes": [],
            "description": "train epoch 1",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 188,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 188,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a77ffad4392243219b9005ab8fc4cbfb"
          }
        },
        "0e7318ef0d6d4fee87b892f20c8f5f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ea907b640f942e992eb67ef2af0b87f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 188/188 [00:27&lt;00:00,  6.73it/s, loss=tensor(6.2344, device=&#x27;cuda:0&#x27;)]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cbf0e28b1e54e88bc431fe614334ed4"
          }
        },
        "0c3c091a86984b1995ce7024b10747c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a77ffad4392243219b9005ab8fc4cbfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ea907b640f942e992eb67ef2af0b87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cbf0e28b1e54e88bc431fe614334ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1c91d93b21e4131927ce46c7ed10c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_107a066a71d64117bad96a35ed809736",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b155921cb194aef8c855550f7d8c334",
              "IPY_MODEL_13cf2d048b2d4221a2dfb47743992169"
            ]
          }
        },
        "107a066a71d64117bad96a35ed809736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b155921cb194aef8c855550f7d8c334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f34c1ccac70e47c4a6dce3d8c9f68db7",
            "_dom_classes": [],
            "description": "train epoch 2",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1686,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1686,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_505a847aaae84149849bf8f0ff999262"
          }
        },
        "13cf2d048b2d4221a2dfb47743992169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fbbdbed29cb480bb2b3c8ed20355fb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1686/1686 [11:56&lt;00:00,  2.35it/s, loss=tensor(5.9491, device=&#x27;cuda:0&#x27;, grad_fn=&lt;DivBackward0&gt;)]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f67cad7421bb438caf1367f774d74e1e"
          }
        },
        "f34c1ccac70e47c4a6dce3d8c9f68db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "505a847aaae84149849bf8f0ff999262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fbbdbed29cb480bb2b3c8ed20355fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f67cad7421bb438caf1367f774d74e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa61fba9bd9941ea80dd162c8b3effee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ddc19af8d80f482abd378c7b0b7aa3ec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d7e00119bd1d447e824a53a68b99fa12",
              "IPY_MODEL_988b65e9d56a460083b19eb2ce8bd509"
            ]
          }
        },
        "ddc19af8d80f482abd378c7b0b7aa3ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7e00119bd1d447e824a53a68b99fa12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c926d43dea9848628167e8def29ebc49",
            "_dom_classes": [],
            "description": "train epoch 2",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 188,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 188,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4db6281360d414f85d7b9751d113c2b"
          }
        },
        "988b65e9d56a460083b19eb2ce8bd509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e6e7de905db4e55bf966b27cd2022c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 188/188 [00:28&lt;00:00,  6.69it/s, loss=tensor(6.0999, device=&#x27;cuda:0&#x27;)]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7dd03ec46d6418c9400de03d17fd03e"
          }
        },
        "c926d43dea9848628167e8def29ebc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4db6281360d414f85d7b9751d113c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e6e7de905db4e55bf966b27cd2022c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7dd03ec46d6418c9400de03d17fd03e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "573c87e6612b410681842c8fe5134783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f39ec837d0e543b99ac3be25268b8499",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d894f0547e2428389f385a47bb6cdee",
              "IPY_MODEL_6dea9368ffa745ffb4336e633a86f5bf"
            ]
          }
        },
        "f39ec837d0e543b99ac3be25268b8499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d894f0547e2428389f385a47bb6cdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d935466f8654424aa7f88a14cd32ec7",
            "_dom_classes": [],
            "description": "train epoch 3",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 1686,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1215,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b68c14776c0423b9998ca47505d41e8"
          }
        },
        "6dea9368ffa745ffb4336e633a86f5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75507e12474d482aaf1a16b9dae0feb2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 72% 1215/1686 [08:37&lt;03:20,  2.35it/s, loss=tensor(5.8221, device=&#x27;cuda:0&#x27;, grad_fn=&lt;DivBackward0&gt;)]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6bfa842d96249ebbee136bfdc12a91e"
          }
        },
        "6d935466f8654424aa7f88a14cd32ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b68c14776c0423b9998ca47505d41e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75507e12474d482aaf1a16b9dae0feb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6bfa842d96249ebbee136bfdc12a91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVDh2D-edqGD",
        "colab_type": "code",
        "outputId": "5fab51eb-8564-4b55-ce06-99f2a56dbd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip3 install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfW3HUarb9g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext import datasets, data\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "import sentencepiece as spm\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQG_5WOHcKNs",
        "colab_type": "code",
        "outputId": "9c8e323d-0f89-410c-9d4c-36b960f33717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "! wget http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz\n",
        "! gunzip -c training-parallel-nc-v13.tgz | tar xvf -"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-22 19:15:13--  http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113157482 (108M) [application/x-gzip]\n",
            "Saving to: ‘training-parallel-nc-v13.tgz.6’\n",
            "\n",
            "training-parallel-n 100%[===================>] 107.92M  18.9MB/s    in 6.6s    \n",
            "\n",
            "2020-02-22 19:15:20 (16.3 MB/s) - ‘training-parallel-nc-v13.tgz.6’ saved [113157482/113157482]\n",
            "\n",
            "training-parallel-nc-v13/\n",
            "training-parallel-nc-v13/news-commentary-v13.ru-en.ru\n",
            "training-parallel-nc-v13/news-commentary-v13.cs-en.en\n",
            "training-parallel-nc-v13/news-commentary-v13.de-en.de\n",
            "training-parallel-nc-v13/news-commentary-v13.ru-en.en\n",
            "training-parallel-nc-v13/news-commentary-v13.zh-en.zh\n",
            "training-parallel-nc-v13/news-commentary-v13.zh-en.en\n",
            "training-parallel-nc-v13/news-commentary-v13.cs-en.cs\n",
            "training-parallel-nc-v13/news-commentary-v13.de-en.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5jkUrXAcJHC",
        "colab_type": "code",
        "outputId": "54c58a0e-5b72-408f-a073-95dca8329de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('training-parallel-nc-v13/news-commentary-v13.ru-en.en') as f:\n",
        "    with open('text.en', 'w') as out:\n",
        "            out.write(f.read().lower())\n",
        "        \n",
        "spm.SentencePieceTrainer.Train('--input=text.en --model_prefix=bpe_en --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgcrTrLncYK6",
        "colab_type": "code",
        "outputId": "38f2d288-406c-44d5-8438-408a9a674bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('training-parallel-nc-v13/news-commentary-v13.ru-en.ru') as f:\n",
        "    with open('text.ru', 'w') as out:\n",
        "            out.write(f.read().lower())\n",
        "\n",
        "spm.SentencePieceTrainer.Train('--input=training-parallel-nc-v13/news-commentary-v13.ru-en.ru --model_prefix=bpe_rus --vocab_size=32000 --character_coverage=0.98 --model_type=bpe')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5GTH8BtcWrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok_ru = spm.SentencePieceProcessor()\n",
        "tok_ru.load('bpe_rus.model')\n",
        "\n",
        "tok_en = spm.SentencePieceProcessor()\n",
        "tok_en.load('bpe_en.model')\n",
        "\n",
        "SRC = data.Field(\n",
        "    fix_length=50,\n",
        "    init_token='<s>',\n",
        "    eos_token='</s>',\n",
        "    lower=True,\n",
        "    tokenize = lambda x: tok_ru.encode_as_pieces(x),\n",
        "    batch_first=True,\n",
        ")\n",
        "\n",
        "TGT = data.Field(\n",
        "    fix_length=50,\n",
        "    init_token='<s>',\n",
        "    eos_token='</s>',\n",
        "    lower=True,\n",
        "    tokenize = lambda x: tok_en.encode_as_pieces(x),\n",
        "    batch_first=True,\n",
        ")\n",
        "\n",
        "fields = (('src', SRC), ('tgt', TGT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bCoDBzZcbqz",
        "colab_type": "code",
        "outputId": "5304a7ef-1cd9-4c2a-83fd-38b91c9683f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('text.ru') as f:\n",
        "    src_snt = list(map(str.strip, f.readlines()))\n",
        "    \n",
        "with open('text.en') as f:\n",
        "    tgt_snt = list(map(str.strip, f.readlines()))\n",
        "    \n",
        "examples = [data.Example.fromlist(x, fields) for x in tqdm(zip(src_snt, tgt_snt))]\n",
        "test = data.Dataset(examples[-1000:], fields)\n",
        "train, valid = data.Dataset(examples[:-1000], fields).split(0.9)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235159it [00:56, 4154.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHUGhQrOcjO-",
        "colab_type": "code",
        "outputId": "6d6659d7-aff0-4c67-ebbf-388de9a7d37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('src: ' + \" \".join(train.examples[100].src))\n",
        "print('tgt: ' + \" \".join(train.examples[100].tgt))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src: ▁в ▁противополож ность ▁этому , ▁при ▁последующих ▁визита х ▁в ▁инди ю ▁я ▁заметил , ▁что ▁принима ющая ▁сторона ▁говорит ▁о ▁необходимости ▁учиться ▁у ▁к итая . ▁об ъ ем ▁торговли ▁между ▁двумя ▁гигантами ▁вырос ▁со ▁ 1 00 ▁миллионов ▁долларов ▁в ▁ 1994 ▁году ▁до ▁почти ▁ 14 ▁миллиардов ▁долларов ▁в ▁прошлом ▁году , ▁и ▁министр ▁торговли ▁и ▁промышленности ▁ин дии ▁предсказал , ▁что ▁к ▁концу ▁этого ▁десятилетия ▁он ▁удвоится .\n",
            "tgt: ▁by ▁contrast , ▁on ▁more ▁recent ▁visits ▁to ▁india , ▁i ▁have ▁found ▁my ▁hosts ▁referring ▁to ▁the ▁need ▁to ▁learn ▁from ▁china .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLUnUCIdclqv",
        "colab_type": "code",
        "outputId": "879abc7c-416e-4530-c2af-f6c6b9a31f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train), len(valid), len(test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210743, 23416, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnJzbFw0codl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TGT.build_vocab(train, min_freq=5)\n",
        "SRC.build_vocab(train, min_freq=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNfyxBkIggAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many \n",
        "    other models.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        \"Take in and process masked src and target sequences.\"\n",
        "        return self.decode(self.encode(src, src_mask), src_mask,\n",
        "                            tgt, tgt_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "    \n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
        "\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"Core encoder is a stack of N layers\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        \"Pass the input (and mask) through each layer in turn.\"\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "    \n",
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module (See citation for details).\"\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "    \n",
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer norm.\n",
        "    Note for code simplicity the norm is first as opposed to last.\n",
        "    \"\"\"\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "    \n",
        "class EncoderLayer(nn.Module):\n",
        "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"Follow Figure 1 (left) for connections.\"\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)\n",
        "\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    \"Generic N layer decoder with masking.\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "        \n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "    \n",
        "class DecoderLayer(nn.Module):\n",
        "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        " \n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        \"Follow Figure 1 (right) for connections.\"\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        return self.sublayer[2](x, self.feed_forward)\n",
        "    \n",
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(subsequent_mask) == 0\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
        "             / np.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        try:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        except:\n",
        "            pass\n",
        "    p_attn = F.softmax(scores, dim = -1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn\n",
        "\n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"Implements Figure 2\"\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "        \n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
        "        query, key, value = \\\n",
        "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "             for l, x in zip(self.linears, (query, key, value))]\n",
        "        \n",
        "        # 2) Apply attention on all the projected vectors in batch. \n",
        "        x, self.attn = attention(query, key, value, mask=mask, \n",
        "                                 dropout=self.dropout)\n",
        "        \n",
        "        # 3) \"Concat\" using a view and apply a final linear. \n",
        "        x = x.transpose(1, 2).contiguous() \\\n",
        "             .view(nbatches, -1, self.h * self.d_k)\n",
        "        return self.linears[-1](x)\n",
        "    \n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"Implements FFN equation.\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
        "    \n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.lut = nn.Embedding(vocab, d_model).cuda()\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lut(x).cuda() * np.sqrt(self.d_model)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
        "                             -(np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
        "      return self.dropout(x)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyKYxVAdctus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batch:\n",
        "    \"Object for holding a batch of data with mask during training.\"\n",
        "    def __init__(self, src, tgt=None, pad=0):\n",
        "        self.src = src\n",
        "        self.src_mask = (src != pad).unsqueeze(-2)\n",
        "        if tgt is not None:\n",
        "            self.trg = tgt[:, :-1]\n",
        "            self.trg_y = tgt[:, 1:]\n",
        "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
        "            self.ntokens = (self.trg_y != pad).data.sum()\n",
        "    \n",
        "    @staticmethod\n",
        "    def make_std_mask(tgt, pad):\n",
        "        \"Create a mask to hide padding and future words.\"\n",
        "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
        "        tgt_mask = tgt_mask & Variable(\n",
        "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
        "        return tgt_mask\n",
        "\n",
        "def make_model(src_vocab, tgt_vocab, N=6, \n",
        "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(h, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
        "                             c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        nn.Linear(d_model, tgt_vocab))\n",
        "    \n",
        "    # This was important from their code. \n",
        "    # Initialize parameters with Glorot / fan_avg.\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model\n",
        "\n",
        "    \n",
        "class BucketIteratorWrapper(DataLoader):\n",
        "    __initialized = False\n",
        "\n",
        "    def __init__(self, iterator: data.Iterator):\n",
        "#         super(BucketIteratorWrapper,self).__init__()\n",
        "        self.batch_size = iterator.batch_size\n",
        "        self.num_workers = 1\n",
        "        self.collate_fn = None\n",
        "        self.pin_memory = False\n",
        "        self.drop_last = False\n",
        "        self.timeout = 0\n",
        "        self.worker_init_fn = None\n",
        "        self.sampler = iterator\n",
        "        self.batch_sampler = iterator\n",
        "        self.__initialized = True\n",
        "\n",
        "    def __iter__(self):\n",
        "        return map(\n",
        "            lambda batch: Batch(batch.src, batch.tgt, pad=TGT.vocab.stoi['<pad>']),\n",
        "            self.batch_sampler.__iter__()\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.batch_sampler)\n",
        "    \n",
        "class MyCriterion:\n",
        "    def __init__(self, generator, pad_idx):\n",
        "        self.generator = generator\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=pad_idx)\n",
        "        self.criterion.cuda()\n",
        "        \n",
        "    def __call__(self, x, batch):\n",
        "        y = batch.trg_y\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.reshape(-1, x.size(-1)), \n",
        "                              y.reshape(-1))  / batch.ntokens\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fjhwsurc0eD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "batch_size = 125\n",
        "num_epochs = 5\n",
        "pad_idx = TGT.vocab.stoi['<pad>']\n",
        "\n",
        "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), \n",
        "                                              batch_sizes=(batch_size, batch_size, batch_size), \n",
        "                                  sort_key=lambda x: len(x.src),\n",
        "                                  shuffle=True,\n",
        "                                  device=DEVICE,\n",
        "                                  sort_within_batch=False)\n",
        "                                  \n",
        "train_iter = BucketIteratorWrapper(train_iter)\n",
        "valid_iter = BucketIteratorWrapper(valid_iter)\n",
        "test_iter = BucketIteratorWrapper(test_iter)\n",
        "\n",
        "model = make_model(len(SRC.vocab), len(TGT.vocab), N=2)\n",
        "model = model.to(DEVICE)\n",
        "criterion = MyCriterion(model.generator, pad_idx)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
        "# # share weights\n",
        "# <TODO>\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2If4ooDc7QP",
        "colab_type": "code",
        "outputId": "e1eff87b-9b0e-4715-c23d-74542b0865d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "2fc78a5f8a3d41008d73058f92b84f42",
            "14e8a7b2184b4ed18ae255da4983786e",
            "607e584c47ce4e3989bb62d110c1dfa9",
            "7c751954933f4e3fa62040e94e6284d7",
            "29178b5f4cc940fea1c2c3bba8fd24ec",
            "fc187127d84a4ff38f7ceaad361247ef",
            "ddf26beedd634369b58ea748231c895f",
            "060cfb2e8d4b444b813bac6677fa6d75",
            "54542e1e57f842d5a5422c56fb170a3a",
            "60564837af5d40779d2f91f236d8590c",
            "065a23d987944fa4a548289dae0c5acf",
            "0e7318ef0d6d4fee87b892f20c8f5f77",
            "0c3c091a86984b1995ce7024b10747c7",
            "a77ffad4392243219b9005ab8fc4cbfb",
            "9ea907b640f942e992eb67ef2af0b87f",
            "7cbf0e28b1e54e88bc431fe614334ed4",
            "d1c91d93b21e4131927ce46c7ed10c3b",
            "107a066a71d64117bad96a35ed809736",
            "1b155921cb194aef8c855550f7d8c334",
            "13cf2d048b2d4221a2dfb47743992169",
            "f34c1ccac70e47c4a6dce3d8c9f68db7",
            "505a847aaae84149849bf8f0ff999262",
            "1fbbdbed29cb480bb2b3c8ed20355fb4",
            "f67cad7421bb438caf1367f774d74e1e",
            "fa61fba9bd9941ea80dd162c8b3effee",
            "ddc19af8d80f482abd378c7b0b7aa3ec",
            "d7e00119bd1d447e824a53a68b99fa12",
            "988b65e9d56a460083b19eb2ce8bd509",
            "c926d43dea9848628167e8def29ebc49",
            "d4db6281360d414f85d7b9751d113c2b",
            "3e6e7de905db4e55bf966b27cd2022c3",
            "f7dd03ec46d6418c9400de03d17fd03e",
            "573c87e6612b410681842c8fe5134783",
            "f39ec837d0e543b99ac3be25268b8499",
            "7d894f0547e2428389f385a47bb6cdee",
            "6dea9368ffa745ffb4336e633a86f5bf",
            "6d935466f8654424aa7f88a14cd32ec7",
            "2b68c14776c0423b9998ca47505d41e8",
            "75507e12474d482aaf1a16b9dae0feb2",
            "c6bfa842d96249ebbee136bfdc12a91e"
          ]
        }
      },
      "source": [
        "def train_epoch(data_iter, model, criterion, optimizer):\n",
        "    total_loss = 0\n",
        "    data_iter = tqdm_notebook(data_iter, total=len(list(iter(data_iter))), desc=f'train epoch {epoch + 1}', leave=True)\n",
        "    counter = 0\n",
        "    for batch in data_iter:\n",
        "        out = model.forward(batch.src, batch.trg, \n",
        "                          batch.src_mask, batch.trg_mask)\n",
        "        loss = criterion(out, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.detach().item() \n",
        "        data_iter.set_postfix(loss = loss)\n",
        "        counter += 1\n",
        "        \n",
        "    total_loss /= counter\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "def valid_epoch(data_iter, model, criterion):\n",
        "    total_loss = 0\n",
        "    data_iter = tqdm_notebook(data_iter, total=len(list(iter(data_iter))), desc=f'valid epoch {epoch + 1}', leave=True)\n",
        "    counter = 0\n",
        "    for batch in data_iter:\n",
        "        with torch.no_grad():\n",
        "            out = model.forward(batch.src, batch.trg, \n",
        "                              batch.src_mask, batch.trg_mask)\n",
        "            loss = criterion(out, batch)\n",
        "            total_loss += loss.detach().item() \n",
        "            data_iter.set_postfix(loss = loss)\n",
        "            counter +=1\n",
        "        \n",
        "    total_loss /= counter\n",
        "    return total_loss\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    loss = train_epoch(train_iter, model, criterion, optimizer)\n",
        "    print('train', loss)\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss = valid_epoch(valid_iter, model, criterion)\n",
        "        scheduler.step(loss)\n",
        "        print('valid', loss)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fc78a5f8a3d41008d73058f92b84f42",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='train epoch 1', max=1686, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train 6.305997338583461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54542e1e57f842d5a5422c56fb170a3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='train epoch 1', max=188, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "valid 5.915760806266298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1c91d93b21e4131927ce46c7ed10c3b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='train epoch 2', max=1686, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train 5.933828900858742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa61fba9bd9941ea80dd162c8b3effee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='train epoch 2', max=188, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "valid 5.767871778062049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "573c87e6612b410681842c8fe5134783",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='train epoch 3', max=1686, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-82a3a83e84de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-82a3a83e84de>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(data_iter, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m                           batch.src_mask, batch.trg_mask)\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7PLh_wDwoJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search(model, src, src_mask, max_len=20, k=5, offset=0):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    start_token = TGT.vocab.stoi[\"<s>\"]\n",
        "    end_token = TGT.vocab.stoi[\"</s>\"]\n",
        "    ys = torch.ones(1, 1).fill_(start_token).type_as(src.data)\n",
        "    beam = [(ys, 0)]\n",
        "    for i in range(max_len):\n",
        "        candidates= []\n",
        "        candidates_proba = []\n",
        "        prev_prob = None\n",
        "        for snt, snt_proba in beam:\n",
        "            if snt[0][-1] == end_token:\n",
        "                candidates.append(snt)\n",
        "                candidates_proba.append(snt_proba)\n",
        "            else:\n",
        "                proba = model.decode(memory, src_mask, snt,\n",
        "                                     subsequent_mask(snt.size(1)).type_as(src.data))\n",
        "                proba = proba[0][i]\n",
        "                best_k = torch.argsort(-proba)[:k].tolist()\n",
        "                proba = proba.tolist()\n",
        "                prev_prob = proba\n",
        "                for tok in best_k:\n",
        "                    candidates.append(torch.cat([snt, torch.ones(1, 1).type_as(src.data).fill_(tok)], dim=1))\n",
        "                    candidates_proba.append(snt_proba + np.log(proba[tok])) \n",
        "         \n",
        "        best_candidates = np.argsort(-np.array(candidates_proba))[offset:k+offset]\n",
        "        beam = [(candidates[j], candidates_proba[j]) for j in best_candidates]\n",
        "    return beam \n",
        "\n",
        "def top_k(pred):\n",
        "    top_k = 500\n",
        "    top_k = min(top_k, pred.size(-1))  # Safety check\n",
        "    # Remove all tokens with a probability less than the last token of the top-k\n",
        "    indices_to_remove = pred < torch.topk(pred, top_k)[0][..., -1, None]\n",
        "    pred[indices_to_remove] = -float('Inf')\n",
        "    probs = torch.softmax(pred, dim=-1)\n",
        "    prev = torch.multinomial(probs, num_samples=1)\n",
        "    return prev\n",
        "\n",
        "def greedy_decode(model, src, src_mask, max_len=10): #, start_symbol, target):\n",
        "    start_symbol, end_token = TGT.vocab.stoi[\"<s>\"], TGT.vocab.stoi[\"</s>\"]\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
        "    for i in range(max_len-1):\n",
        "        out = model.decode(memory, src_mask, \n",
        "                           Variable(ys), \n",
        "                           Variable(subsequent_mask(ys.size(1))\n",
        "                                    .type_as(src.data)))\n",
        "        prob = model.generator(out[:, -1])\n",
        "        next_word = top_k(prob)[0]\n",
        "        next_word += 2\n",
        "        next_word = next_word.data[0]\n",
        "        ys = torch.cat([ys, \n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "        if TARGET_TXT.vocab.itos[ys[0][-1]] == \"</s>\":\n",
        "          break\n",
        "    return ys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN2zh83HdAr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(valid_iter):\n",
        "        src = batch.src\n",
        "        src_key_padding_mask = src != SRC.vocab.stoi[\"<pad>\"]\n",
        "        beam = beam_search(model, src, src_key_padding_mask)\n",
        "        seq = []\n",
        "        for i in range(1, src.size(1)):\n",
        "            sym = SRC.vocab.itos[src[0, i]]\n",
        "            if sym == \"</s>\": break\n",
        "            seq.append(sym)\n",
        "        seq = tok_ru.decode_pieces(seq)\n",
        "        print(\"\\nSource:\", seq)\n",
        "        \n",
        "        print(\"Translation:\")\n",
        "        for pred, pred_proba in beam:                \n",
        "            seq = []\n",
        "            for i in range(1, pred.size(1)):\n",
        "                sym = TGT.vocab.itos[pred[0, i]]\n",
        "                if sym == \"</s>\": break\n",
        "                seq.append(sym)\n",
        "            seq = tok_en.decode_pieces(seq)\n",
        "            print(f\"pred {pred_proba:.2f}:\", seq)\n",
        "                \n",
        "        seq = []\n",
        "        for i in range(1, batch.trg.size(1)):\n",
        "            sym = TGT.vocab.itos[batch.trg[0, i]]\n",
        "            if sym == \"</s>\": break\n",
        "            seq.append(sym)\n",
        "        seq = tok_en.decode_pieces(seq)\n",
        "        print(\"Target:\", seq)\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLedc859dDmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS4haQh5XRAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_iter = tqdm_notebook(test_iter, total=len(list(iter(test_iter))), desc=f'valid epoch {epoch + 1}', leave=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aosFUSfzdI1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b84d981-b3de-4b46-8a0c-73f9f9dc77c8"
      },
      "source": [
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_iter):\n",
        "        for sent in range(len(batch.src)):\n",
        "            src = batch.src[sent:sent+1]\n",
        "            src_key_padding_mask = src != SRC.vocab.stoi[\"<pad>\"]\n",
        "            beam = beam_search(model, src, src_key_padding_mask, k=5, offset=0)\n",
        "            for pred, pred_proba in beam[:1]:                \n",
        "                seq = []\n",
        "                for i in range(1, pred.size(1)):\n",
        "                    sym = TGT.vocab.itos[pred[0, i]]\n",
        "                    if sym == \"</s>\": break\n",
        "                    seq.append(sym)\n",
        "                seq = tok_en.decode_pieces(seq)\n",
        "                my_trg = batch.trg[sent:sent+1].tolist()[0]\n",
        "                my_ref = []\n",
        "                for i in range(1, batch.trg.size(1)):\n",
        "                     m_trg =  TGT.vocab.itos[my_trg[i]]\n",
        "                     if m_trg == \"</s>\" or m_trg  == \"<pad>\": break\n",
        "                     my_ref.append(m_trg)\n",
        "                my_ref = tok_en.decode_pieces(my_ref)\n",
        "                hypotheses.append(seq.split())\n",
        "                references.append(my_ref.split())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [07:35<00:00, 57.00s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2byJN9pydMvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1a552890-0de5-4a8b-d751-bbc3c0e76ff6"
      },
      "source": [
        "corpus_bleu(references, hypotheses, \n",
        "            # smoothing_function=translate.bleu_score.SmoothingFunction().method3,\n",
        "            auto_reweigh=True\n",
        "           )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15967184337873702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}